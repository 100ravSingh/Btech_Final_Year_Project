{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import random\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(723)\n",
    "np.random.seed(723)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initilialize_poplulation(numberOfParents):\n",
    "    learningRate = np.empty([numberOfParents, 1])\n",
    "    nEstimators = np.empty([numberOfParents, 1], dtype = np.uint8)\n",
    "    maxDepth = np.empty([numberOfParents, 1], dtype = np.uint8)\n",
    "    minChildWeight = np.empty([numberOfParents, 1])\n",
    "    gammaValue = np.empty([numberOfParents, 1])\n",
    "    subSample = np.empty([numberOfParents, 1])\n",
    "    colSampleByTree =  np.empty([numberOfParents, 1])\n",
    "\n",
    "    for i in range(numberOfParents):\n",
    "        print(i)\n",
    "        learningRate[i] = round(random.uniform(0.01, 1), 2)\n",
    "        nEstimators[i] = random.randrange(10, 1500, step = 25)\n",
    "        maxDepth[i] = int(random.randrange(1, 10, step= 1))\n",
    "        minChildWeight[i] = round(random.uniform(0.01, 10.0), 2)\n",
    "        gammaValue[i] = round(random.uniform(0.01, 10.0), 2)\n",
    "        subSample[i] = round(random.uniform(0.01, 1.0), 2)\n",
    "        colSampleByTree[i] = round(random.uniform(0.01, 1.0), 2)\n",
    "    \n",
    "    population = np.concatenate((learningRate, nEstimators, maxDepth, minChildWeight, gammaValue, subSample, colSampleByTree), axis= 1)\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create fitness function that will predict F1_score    \n",
    "\n",
    "def fitness_f1score(y_true, y_pred):\n",
    "    fitness = round((f1_score(y_true, y_pred, average='weighted')), 4)\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the data annd find fitness score\n",
    "def train_population(population, dMatrixTrain, dMatrixtest, y_test):\n",
    "    fScore = []\n",
    "    for i in range(population.shape[0]):\n",
    "        param = { 'objective':'binary:logistic',\n",
    "              'learning_rate': population[i][0], \n",
    "              'max_depth': int(population[i][2]), \n",
    "              'min_child_weight': population[i][3],\n",
    "              'gamma': population[i][4], \n",
    "              'subsample': population[i][5],\n",
    "              'colsample_bytree': population[i][6],\n",
    "              'seed': 24,'verbosity': 0 }\n",
    "        num_round = 500\n",
    "        xgbT = xgb.train(param, dMatrixTrain, num_round)\n",
    "        preds = xgbT.predict(dMatrixtest)\n",
    "        preds = preds>0.5\n",
    "        fScore.append(fitness_f1score(y_test, preds))\n",
    "    return fScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select parents for mating\n",
    "def new_parents_selection(population, fitness, numParents):\n",
    "    selectedParents = np.empty((numParents, population.shape[1])) #create an array to store fittest parents\n",
    "    \n",
    "    #find the top best performing parents\n",
    "    for parentId in range(numParents):\n",
    "        bestFitnessId = np.where(fitness == np.max(fitness))\n",
    "        bestFitnessId  = bestFitnessId[0][0]\n",
    "        selectedParents[parentId, :] = population[bestFitnessId, :]\n",
    "        fitness[bestFitnessId] = -1 #set this value to negative, in case of F1-score, so this parent is not selected again\n",
    "    return selectedParents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Mate these parents to create chilren having parameters from these parents (we are using uniform crossover method)\n",
    "'''\n",
    "def crossover_uniform(parents, childrenSize):\n",
    "    \n",
    "    crossoverPointIndex = np.arange(0, np.uint8(childrenSize[1]), 1, dtype= np.uint8) #get all the index\n",
    "    crossoverPointIndex1 = np.random.randint(0, np.uint8(childrenSize[1]), np.uint8(childrenSize[1]/2)) # select half  of the indexes randomly\n",
    "    crossoverPointIndex2 = np.array(list(set(crossoverPointIndex) - set(crossoverPointIndex1))) #select leftover indexes\n",
    "    \n",
    "    children = np.empty(childrenSize)\n",
    "    \n",
    "    '''\n",
    "    Create child by choosing parameters from two paraents selected using new_parent_selection function. The parameter values\n",
    "    will be picked from the indexes, which were randomly selected above. \n",
    "    '''\n",
    "    for i in range(childrenSize[0]):\n",
    "        \n",
    "        #find parent 1 index \n",
    "        parent1_index = i%parents.shape[0]\n",
    "        #find parent 2 index\n",
    "        parent2_index = (i+1)%parents.shape[0]\n",
    "        #insert parameters based on random selected indexes in parent 1\n",
    "        children[i, crossoverPointIndex1] = parents[parent1_index, crossoverPointIndex1]\n",
    "        #insert parameters based on random selected indexes in parent 1\n",
    "        children[i, crossoverPointIndex2] = parents[parent2_index, crossoverPointIndex2]\n",
    "    return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Introduce some mutation in the children. In case of XGboost we will introdcue mutation randomly on each parameter one at a time,\n",
    "based on which parameter is selected at random. Initially, we will define the maximum/minimum value that is allowed for the parameter, to prevent the\n",
    "out the range error during runtime. Subsequently, we will generate mutation value and add it to the parameter, and return the mutated offspring!!!\n",
    "'''\n",
    "\n",
    "def mutation(crossover, numberOfParameters):\n",
    "    #Define minimum and maximum values allowed for each parameter\n",
    "\n",
    "    minMaxValue = np.zeros((numberOfParameters, 2))\n",
    "    \n",
    "    minMaxValue[0:] = [0.01, 1.0] #min/max learning rate\n",
    "    minMaxValue[1, :] = [10, 2000] #min/max n_estimator\n",
    "    minMaxValue[2, :] = [1, 15] #min/max depth\n",
    "    minMaxValue[3, :] = [0, 10.0] #min/max child_weight\n",
    "    minMaxValue[4, :] = [0.01, 10.0] #min/max gamma\n",
    "    minMaxValue[5, :] = [0.01, 1.0] #min/maxsubsample\n",
    "    minMaxValue[6, :] = [0.01, 1.0] #min/maxcolsample_bytree\n",
    " \n",
    "    # Mutation changes a single gene in each offspring randomly.\n",
    "    mutationValue = 0\n",
    "    parameterSelect = np.random.randint(0, 7, 1)\n",
    "    print(parameterSelect)\n",
    "    if parameterSelect == 0: #learning_rate\n",
    "        mutationValue = round(np.random.uniform(-0.5, 0.5), 2)\n",
    "    if parameterSelect == 1: #n_estimators\n",
    "        mutationValue = np.random.randint(-200, 200, 1)\n",
    "    if parameterSelect == 2: #max_depth\n",
    "        mutationValue = np.random.randint(-5, 5, 1)\n",
    "    if parameterSelect == 3: #min_child_weight\n",
    "        mutationValue = round(np.random.uniform(5, 5), 2)\n",
    "    if parameterSelect == 4: #gamma\n",
    "        mutationValue = round(np.random.uniform(-2, 2), 2)\n",
    "    if parameterSelect == 5: #subsample\n",
    "        mutationValue = round(np.random.uniform(-0.5, 0.5), 2)\n",
    "    if parameterSelect == 6: #colsample\n",
    "        mutationValue = round(np.random.uniform(-0.5, 0.5), 2)\n",
    "  \n",
    "    #indtroduce mutation by changing one parameter, and set to max or min if it goes out of range\n",
    "    for idx in range(crossover.shape[0]):\n",
    "        crossover[idx, parameterSelect] = crossover[idx, parameterSelect] + mutationValue\n",
    "        if(crossover[idx, parameterSelect] > minMaxValue[parameterSelect, 1]):\n",
    "            crossover[idx, parameterSelect] = minMaxValue[parameterSelect, 1]\n",
    "        if(crossover[idx, parameterSelect] < minMaxValue[parameterSelect, 0]):\n",
    "            crossover[idx, parameterSelect] = minMaxValue[parameterSelect, 0]    \n",
    "    return crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function will allow us to genrate the heatmap for various parameters and fitness to visualize \n",
    "how each parameter and fitness changes with each generation\n",
    "'''\n",
    "\n",
    "def plot_parameters(numberOfGenerations, numberOfParents, parameter, parameterName):\n",
    "    #inspired from https://matplotlib.org/gallery/images_contours_and_fields/image_annotated_heatmap.html\n",
    "    generationList = [\"Gen {}\".format(i) for i in range(numberOfGenerations+1)]\n",
    "    populationList = [\"Parent {}\".format(i) for i in range(numberOfParents)]\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(parameter, cmap=plt.get_cmap('YlOrBr'))\n",
    "    \n",
    "    # show ticks\n",
    "    ax.set_xticks(np.arange(len(populationList)))\n",
    "    ax.set_yticks(np.arange(len(generationList)))\n",
    "    \n",
    "    # show labels\n",
    "    ax.set_xticklabels(populationList)\n",
    "    ax.set_yticklabels(generationList)\n",
    "    \n",
    "    # set ticks at 45 degrees and rotate around anchor\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    \n",
    "    \n",
    "    # insert the value of the parameter in each cell\n",
    "    for i in range(len(generationList)):\n",
    "        for j in range(len(populationList)):\n",
    "            text = ax.text(j, i, parameter[i, j],\n",
    "                           ha=\"center\", va=\"center\", color=\"k\")\n",
    "    \n",
    "    ax.set_title(\"Change in the value of \" + parameterName)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
